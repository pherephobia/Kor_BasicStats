<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Better Understanding for Linear Model | Basic Statistics and Data Analysis: Korean Version</title>
  <meta name="description" content="Chapter 7 Better Understanding for Linear Model | Basic Statistics and Data Analysis: Korean Version" />
  <meta name="generator" content="bookdown 0.12 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Better Understanding for Linear Model | Basic Statistics and Data Analysis: Korean Version" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Better Understanding for Linear Model | Basic Statistics and Data Analysis: Korean Version" />
  
  
  

<meta name="author" content="Sanghoon Park" />


<meta name="date" content="2019-10-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="intoduction-to-simple-linear-regression-model.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction to <strong>R</strong></a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#기본-동작에-관한-소개"><i class="fa fa-check"></i><b>2.1</b> 기본 동작에 관한 소개</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#r의-연산자operations"><i class="fa fa-check"></i><b>2.2</b> <strong>R</strong>의 연산자(operations)</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#r의-기본적인-자료-유형"><i class="fa fa-check"></i><b>2.3</b> <strong>R</strong>의 기본적인 자료 유형</a><ul>
<li class="chapter" data-level="2.3.1" data-path="intro.html"><a href="intro.html#논리형-연산자-logical-operators"><i class="fa fa-check"></i><b>2.3.1</b> 논리형 연산자 (Logical operators)</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#벡터-vectors"><i class="fa fa-check"></i><b>2.4</b> 벡터 (Vectors)</a></li>
<li class="chapter" data-level="2.5" data-path="intro.html"><a href="intro.html#매트릭스-matrices"><i class="fa fa-check"></i><b>2.5</b> 매트릭스 (Matrices)</a></li>
<li class="chapter" data-level="2.6" data-path="intro.html"><a href="intro.html#데이터프레임-data-frame"><i class="fa fa-check"></i><b>2.6</b> 데이터프레임 (Data frame)</a></li>
<li class="chapter" data-level="2.7" data-path="intro.html"><a href="intro.html#티블-tibbles"><i class="fa fa-check"></i><b>2.7</b> 티블 (Tibbles)</a></li>
<li class="chapter" data-level="2.8" data-path="intro.html"><a href="intro.html#패키지-packages"><i class="fa fa-check"></i><b>2.8</b> 패키지 (Packages)</a></li>
<li class="chapter" data-level="2.9" data-path="intro.html"><a href="intro.html#디렉토리-생성-코드"><i class="fa fa-check"></i><b>2.9</b> 디렉토리 생성 코드</a></li>
<li class="chapter" data-level="2.10" data-path="intro.html"><a href="intro.html#용례-a-working-example"><i class="fa fa-check"></i><b>2.10</b> 용례 (A working example)</a></li>
<li class="chapter" data-level="2.11" data-path="intro.html"><a href="intro.html#기타-참고자료"><i class="fa fa-check"></i><b>2.11</b> 기타 참고자료</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch3.html"><a href="ch3.html"><i class="fa fa-check"></i><b>3</b> Introduction to Data</a><ul>
<li class="chapter" data-level="3.1" data-path="ch3.html"><a href="ch3.html#작업-디렉토리-설정"><i class="fa fa-check"></i><b>3.1</b> 작업 디렉토리 설정</a></li>
<li class="chapter" data-level="3.2" data-path="ch3.html"><a href="ch3.html#무작위-추출random-draws"><i class="fa fa-check"></i><b>3.2</b> 무작위 추출(Random Draws)</a></li>
<li class="chapter" data-level="3.3" data-path="ch3.html"><a href="ch3.html#루프-반복loops"><i class="fa fa-check"></i><b>3.3</b> 루프-반복(Loops)</a></li>
<li class="chapter" data-level="3.4" data-path="ch3.html"><a href="ch3.html#rplots를-파일의-형태로-저장하기"><i class="fa fa-check"></i><b>3.4</b> Rplots를 파일의 형태로 저장하기</a></li>
<li class="chapter" data-level="3.5" data-path="ch3.html"><a href="ch3.html#데이터-다루기-기본"><i class="fa fa-check"></i><b>3.5</b> 데이터 다루기 기본</a><ul>
<li class="chapter" data-level="3.5.1" data-path="ch3.html"><a href="ch3.html#데이터에-새로운-변수-더미변수-만들기"><i class="fa fa-check"></i><b>3.5.1</b> 데이터에 새로운 변수 &amp; 더미변수 만들기</a></li>
<li class="chapter" data-level="3.5.2" data-path="ch3.html"><a href="ch3.html#다른-유형의-데이터-불러오기-loading-data-in-different-formats"><i class="fa fa-check"></i><b>3.5.2</b> 다른 유형의 데이터 불러오기 (Loading data in different formats)</a></li>
<li class="chapter" data-level="3.5.3" data-path="ch3.html"><a href="ch3.html#자료-머징하기-using-data-merging"><i class="fa fa-check"></i><b>3.5.3</b> 자료 머징하기 (Using Data Merging)</a></li>
<li class="chapter" data-level="3.5.4" data-path="ch3.html"><a href="ch3.html#예제-correlatesofwar.org에서-capabilities-데이터셋을-불러오기3-3"><i class="fa fa-check"></i><b>3.5.4</b> 예제: correlatesofwar.org에서 capabilities 데이터셋을 불러오기[^3-3]</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="ch3.html"><a href="ch3.html#요약통계표를-.tex-파일로-저장하기"><i class="fa fa-check"></i><b>3.6</b> 요약통계표를 .tex 파일로 저장하기</a></li>
<li class="chapter" data-level="3.7" data-path="ch3.html"><a href="ch3.html#서로-다른-분석수준lower-higher-통합하기"><i class="fa fa-check"></i><b>3.7</b> 서로 다른 분석수준(lower &amp; higher) 통합하기</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="probability-into-r.html"><a href="probability-into-r.html"><i class="fa fa-check"></i><b>4</b> Probability into R</a><ul>
<li class="chapter" data-level="4.1" data-path="probability-into-r.html"><a href="probability-into-r.html#주사위굴리기-게임"><i class="fa fa-check"></i><b>4.1</b> 주사위굴리기 게임!</a></li>
<li class="chapter" data-level="4.2" data-path="probability-into-r.html"><a href="probability-into-r.html#동전-던지기"><i class="fa fa-check"></i><b>4.2</b> 동전 던지기</a></li>
<li class="chapter" data-level="4.3" data-path="probability-into-r.html"><a href="probability-into-r.html#독립사건-시뮬레이션"><i class="fa fa-check"></i><b>4.3</b> 독립사건 시뮬레이션</a></li>
<li class="chapter" data-level="4.4" data-path="probability-into-r.html"><a href="probability-into-r.html#종속사건-시뮬레이션"><i class="fa fa-check"></i><b>4.4</b> 종속사건 시뮬레이션</a></li>
<li class="chapter" data-level="4.5" data-path="probability-into-r.html"><a href="probability-into-r.html#분포distribution"><i class="fa fa-check"></i><b>4.5</b> 분포(Distribution)</a><ul>
<li class="chapter" data-level="4.5.1" data-path="probability-into-r.html"><a href="probability-into-r.html#정규분포-the-normal-distribution"><i class="fa fa-check"></i><b>4.5.1</b> 정규분포 (The normal distribution)</a></li>
<li class="chapter" data-level="4.5.2" data-path="probability-into-r.html"><a href="probability-into-r.html#이항분포-binomial-distribution"><i class="fa fa-check"></i><b>4.5.2</b> 이항분포 (Binomial distribution)</a></li>
<li class="chapter" data-level="4.5.3" data-path="probability-into-r.html"><a href="probability-into-r.html#포와송-분포-poison-distribution"><i class="fa fa-check"></i><b>4.5.3</b> 포와송 분포 (Poison distribution)</a></li>
<li class="chapter" data-level="4.5.4" data-path="probability-into-r.html"><a href="probability-into-r.html#음이항-분포-negative-binomial-distribution"><i class="fa fa-check"></i><b>4.5.4</b> 음이항 분포 (Negative Binomial Distribution)</a></li>
<li class="chapter" data-level="4.5.5" data-path="probability-into-r.html"><a href="probability-into-r.html#f-분포-f-distribution"><i class="fa fa-check"></i><b>4.5.5</b> F 분포 (F Distribution)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="foundation-of-inference.html"><a href="foundation-of-inference.html"><i class="fa fa-check"></i><b>5</b> Foundation of Inference</a><ul>
<li class="chapter" data-level="5.1" data-path="foundation-of-inference.html"><a href="foundation-of-inference.html#표본을-통한-모집단-추론-infer-population-using-samples"><i class="fa fa-check"></i><b>5.1</b> 표본을 통한 모집단 추론 (Infer Population using Samples)</a></li>
<li class="chapter" data-level="5.2" data-path="foundation-of-inference.html"><a href="foundation-of-inference.html#평균의-차이difference-of-means-그리고-분산분석analysis-of-variance-anova"><i class="fa fa-check"></i><b>5.2</b> 평균의 차이(difference of means), 그리고 분산분석(analysis of variance, ANOVA)</a><ul>
<li class="chapter" data-level="5.2.1" data-path="foundation-of-inference.html"><a href="foundation-of-inference.html#평균-차이를-보는-이유"><i class="fa fa-check"></i><b>5.2.1</b> 평균 차이를 보는 이유</a></li>
<li class="chapter" data-level="5.2.2" data-path="foundation-of-inference.html"><a href="foundation-of-inference.html#t-검정을-이용한-두-평균의-차이"><i class="fa fa-check"></i><b>5.2.2</b> t-검정을 이용한 두 평균의 차이</a></li>
<li class="chapter" data-level="5.2.3" data-path="foundation-of-inference.html"><a href="foundation-of-inference.html#분산분석anova을-이용해-여러-평균을-비교하기"><i class="fa fa-check"></i><b>5.2.3</b> 분산분석(ANOVA)을 이용해 여러 평균을 비교하기</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="foundation-of-inference.html"><a href="foundation-of-inference.html#비율-차이-교차표와-카이스퀘어-검정chi-squared-tests"><i class="fa fa-check"></i><b>5.3</b> 비율 차이: 교차표와 카이스퀘어 검정(chi-squared tests)</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="intoduction-to-simple-linear-regression-model.html"><a href="intoduction-to-simple-linear-regression-model.html"><i class="fa fa-check"></i><b>6</b> Intoduction to Simple Linear Regression Model</a><ul>
<li class="chapter" data-level="6.1" data-path="intoduction-to-simple-linear-regression-model.html"><a href="intoduction-to-simple-linear-regression-model.html#회귀분석의-이해-기울기의-검정"><i class="fa fa-check"></i><b>6.1</b> 회귀분석의 이해: 기울기의 검정</a></li>
<li class="chapter" data-level="6.2" data-path="intoduction-to-simple-linear-regression-model.html"><a href="intoduction-to-simple-linear-regression-model.html#좀-더-복잡한-회귀분석의-이해-다변량-회귀분석-multivariate-regression에-들어서기"><i class="fa fa-check"></i><b>6.2</b> 좀 더 복잡한 회귀분석의 이해: 다변량 회귀분석 (multivariate regression)에 들어서기</a></li>
<li class="chapter" data-level="6.3" data-path="intoduction-to-simple-linear-regression-model.html"><a href="intoduction-to-simple-linear-regression-model.html#단순회귀분석-심화"><i class="fa fa-check"></i><b>6.3</b> 단순회귀분석 심화</a></li>
<li class="chapter" data-level="6.4" data-path="intoduction-to-simple-linear-regression-model.html"><a href="intoduction-to-simple-linear-regression-model.html#이제-계수값에-대한-t검정을-수행해보겠습니다."><i class="fa fa-check"></i><b>6.4</b> 이제 계수값에 대한 t검정을 수행해보겠습니다.</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="better-understanding-for-linear-model.html"><a href="better-understanding-for-linear-model.html"><i class="fa fa-check"></i><b>7</b> Better Understanding for Linear Model</a><ul>
<li class="chapter" data-level="7.1" data-path="better-understanding-for-linear-model.html"><a href="better-understanding-for-linear-model.html#추정estimation"><i class="fa fa-check"></i><b>7.1</b> 추정(Estimation)</a><ul>
<li class="chapter" data-level="7.1.1" data-path="better-understanding-for-linear-model.html"><a href="better-understanding-for-linear-model.html#점추정과-구간추정point-estimation-and-interval-estimation"><i class="fa fa-check"></i><b>7.1.1</b> 점추정과 구간추정(point estimation and interval estimation)</a></li>
<li class="chapter" data-level="7.1.2" data-path="better-understanding-for-linear-model.html"><a href="better-understanding-for-linear-model.html#신뢰구간-평균과-비율"><i class="fa fa-check"></i><b>7.1.2</b> 신뢰구간: 평균과 비율</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="better-understanding-for-linear-model.html"><a href="better-understanding-for-linear-model.html#유의성-검정significnace-tests"><i class="fa fa-check"></i><b>7.2</b> 유의성 검정(Significnace Tests)</a><ul>
<li class="chapter" data-level="7.2.1" data-path="better-understanding-for-linear-model.html"><a href="better-understanding-for-linear-model.html#유의성-검정을-이루는-다섯-가지-부분"><i class="fa fa-check"></i><b>7.2.1</b> 유의성 검정을 이루는 다섯 가지 부분</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Basic Statistics and Data Analysis: Korean Version</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="better-understanding-for-linear-model" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Better Understanding for Linear Model</h1>
<p>제6장에서 단순선형회귀모델(simple linear regression model)에 대한 기본적인 내용들을 주로 <strong>R</strong>코드와 통계치들을 중심으로 살펴보았다면, 이 장에서는 설명변수가 2개 이상인 다중선형회귀모델(multiple linear regression model)로 나아가기 이전에 짚고 넘어가야할 선형모델에 대한 이론적 배경들을 짚어보고자 합니다.</p>
<p>이론적인 측면에서는 제4장과 제5장에서 이어진다고 할 수 있습니다. 구체적으로 이 장은 추정(estimation)-유의성 검정(significance tests)-두 집단의 비교(comparison of two groups)-선형회귀모델과 상관관계 순으로 앞선 장들에서 놓치고 넘어갈 수 있었던 이론적인 논의들을 다루어보고자 합니다.</p>
<div id="추정estimation" class="section level2">
<h2><span class="header-section-number">7.1</span> 추정(Estimation)</h2>
<p>첫 번째 절에서는 추정의 문제를 살펴볼 것입니다. 통계방법을 이용하여 우리는 무엇을 추정하려고 하는 것인지, 그리고 추정에는 어떠한 종류가 있는지, 데이터에 따라 우리가 추정해야하기 위해 주목해야하는 것이 무엇인지 등을 다룹니다.</p>
<div id="점추정과-구간추정point-estimation-and-interval-estimation" class="section level3">
<h3><span class="header-section-number">7.1.1</span> 점추정과 구간추정(point estimation and interval estimation)</h3>
<p>무엇인가를 추정한다는 것은 표본과 모집단의 관계로 설명할 수 있습니다. 현실세계 속에서 우리가 사회현상에 대한 모집단을 관측한다는 것은 불가능에 가깝습니다. 따라서 우리는 관측가능한 자료, 표본(sample) 데이터를 통하여 모집단의 모수(parameters)의 값을 “추정”하고자 합니다. 즉, 추정의 목적은 본질적으로는 표본을 통하여 모집단의 특성을 이해하는 것에 있습니다. 이 지점에서 제5장에서 살펴보았던 “추론”의 개념이 등장합니다. 모집단을 확보할 수 없으니, 모집단을 잘 대표할 것이라고 기대되는 그 일부, 표본을 통해 모집단이 이러이러할 것이다—라는 추론(inference)을 하게 되는 것이지요.</p>
<p>정량적 변수들을 이용해서 우리는 모집단의 평균(mean)을 추정할 수 있으며, 명목형 변수-분류형 변수를 이용해서는 각 부류가 전체 분류에서 차지하는 비율(proportion)을 추정할 수 있습니다.</p>
<p>통계학에서는 여러 가지 유사한 용어들이 나오고, 그것들을 구분하여 사용하는 것이 중요합니다. 예를 들어, 지금 언급하고 있는 추정(estimation)과 추정량(estimator)은 서로 다른 개념입니다.</p>
<ul>
<li><p>추정량(estimator)이란 표본의 비율(sample proportion), 표본의 평균(saple mean)과 같은 모집단의 모수를 추정하기 위한 특정한 통계치(statistic)을 의미합니다.</p></li>
<li><p>이때 통계치(statistic)은 모집단의 모수(parameter)와 대칭적 관계로 이해할 수 있으며, 표본의 통계적 특성을 의미한다고 볼 수 있습니다.</p></li>
<li><p>한편, 추정값(estimate)은 표본의 특정한 값을 지칭합니다. 예를 들어, 표본의 비율(estimator)의 값(estimate)이 0.73이라는 식으로 표현할 수 있습니다.</p></li>
</ul>
<p>모든 추정이 동일하지는 않습니다. 왜냐하면 우리는 모집단을 알지 못하여 표본을 가지고 모집단의 특성을 추정, 추론하기 때문에 우리의 추정에는 불확실성(uncertainty)이 존재하는 탓입니다. 여기서는 점추정량(point estimate)과 구간추정량(interval estimate)을 살펴보고자 합니다.</p>
<ul>
<li><p>점추정량이란 모수의 값(parameter value)에 대해 최선의 추측이라고 할 수 있는 단 하나의 통계치(single statistic value)를 의미합니다. 즉, 표본을 통해 모집단의 평균이 0.5일 것이라고 말할 때, 우리는 그 0.5를 점추정량이라고 말할 수 있습니다.</p></li>
<li><p>반면, 구간추정량은 점추정량 둘러싼 구간을 의미하는데, 모수값을 포함할 것이라고 기대되는 “고정된 신뢰수준”(fixed confidence level)을 보여주는 구간<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>이라고 할 수 있습니다. 이 점에서 우리는 이 구간추정량에 대해 신뢰구간(confidence interval)이라고 합니다.</p></li>
</ul>
<p>추정, 추정량, 추정값을 이해하는 것은 아마도 모집단의 모수를 제대로, 잘 추정하는 추정량을 얻기 위해서일 것입니다. 그렇다면 좋은 추정량은 무엇일까요? 크게 두 가지 기준을 생각해볼 수 있습니다.</p>
<p>첫째는 불편성(unbiasness)입니다. 이는 추정량의 표집분포가 모집단 값을 중심으로 분포되어 있어야 한다는 것을 의미합니다. 즉, 추정량은 표본을 바탕으로 한 것이기 때문에 모수를 추정하는 데 있어서 불확실성을 내표할수밖에 없지만, 그 불확실성이 모수를 중심으로 퍼져있는 것이라면 우리는 기대값—평균이나 비율 등을 이용하여 모수를 추정할 수 있습니다. 만약 추정량이 편향되어 있다면(biased), 평균적으로 모수를 과소추정(underestimate)하거나 과대추정(overestimate)한다면 우리는 그 결과를 신뢰하기 어려울 것입니다.</p>
<p>두 번째로는 효율성(efficiency)이 있습니다. 가능한 한 작은 표준오차를 통하여 추정할수록 우리는 그 추정량이 다른 추정량에 비하여 모수를 평균적으로 더 ‘가깝게’ 추정하는 효율적인 추정량일 것이라고 기대하게 됩니다. 표준오차가 크다는 것은 그만큼 불확실하다는 것이고 우리가 모수값을 추정하는 데 믿기 어려운 결과라는 의미입니다. 그렇다면 우리는 그 불확실성을 보정하기 위하여 추가적인 조치들을 취해야할 것이고, 그 결과는 비효율적(inefficient)이라고 할 수 있습니다.</p>
<p>동시에 신뢰구간의 문제도 함께 생각해볼 필요가 있습니다. 신뢰구간은 앞서 언급했다시피 모수값을 포함하고 있을 것이라고 기대되는 수의 구간(interval of numbers)입니다. 그리고 그 구간을 계산해내는 방법이 모수를 포함할 것이라고 기대되는 확률을 우리는 신뢰수준(confidence level)이라고 정의합니다. 사회과학에서 대다수의 연구들은 0.95나 0.99와 같은 거의 1에 가까운 신뢰수준을 사용합니다.</p>
<p>신뢰구간은 대개 <strong>점추정값 <span class="math inline">\(\pm\)</span> 오차한계(margin of error)</strong>로 표현되며, 이때 오차한계란 점추정량의 표집분포(sampling distribution)가 어떻게 분포되어 있는지를 보여주는 것이라고 할 수 있습니다. 즉, 수없이 표본을 많이 뽑아봤을 때, 표집이라는 과정에서 본질적으로 불확실할수밖에 없는 점추정값이 어떻게 분포하느냐를 보여주는 것이죠. 따라서 오차한계는 점추정량에 대한 신뢰수준에 따라 달라지는데, 95% 신뢰수준에서 오차한계는 대략 점추정치로부터 <span class="math inline">\(\pm 2\times\)</span>표준오차 정도라고 할 수 있습니다.</p>
</div>
<div id="신뢰구간-평균과-비율" class="section level3">
<h3><span class="header-section-number">7.1.2</span> 신뢰구간: 평균과 비율</h3>
<p>데이터의 특성에 따라 우리는 서로 다른 추정량을 통해 모집단에 대해 추론합니다. 예를 들어, 정량적-연속형 변수일 경우에는 평균을 통해 그 자료를 대표하는 값을 보여줄 수 있지만, 명목형-분류형 변수일 경우에는 비율을 대표값이라고 할 수 있습니다. 따라서 신뢰구간을 구하는 것도 데이터에 따라서 다르게 보여줄 수 있습니다.</p>
<div id="비율의-신뢰구간" class="section level4">
<h4><span class="header-section-number">7.1.2.1</span> 비율의 신뢰구간</h4>
<p>명목형-분류형 변수일 경우, 우리는 비율에 대한 신뢰구간을 보여줄 수 있습니다. 표본의 비율은 <span class="math inline">\(\hat{\pi}\)</span>로 나타내며, 이는 어떤 카테고리에 따른 존부(存否)를 보여주는 것이라고 할 수 있습니다. 예를 들어, 이항변수(binary variable)일 때, <span class="math inline">\(\hat{\pi}\)</span>는 전체 관측치 중에서 <span class="math inline">\(y = 1\)</span>가 몇 개 속해있는지를 보여주는 평균이라고 할 수 있습니다.</p>
<p>모집단의 비율은 즉, <span class="math inline">\(P(1) = \pi\)</span>와 <span class="math inline">\(P(0) = 1-\pi\)</span>라는 확률분포의 평균 <span class="math inline">\(\mu\)</span>라고 할 수 있습니다. 이때, 이 확률분포의 표준편차는 <span class="math inline">\(\sigma = \sqrt{\pi(1-\pi)}\)</span>로 나타낼 수 있으며, 표본 비율에 대한 표준오차는 <span class="math inline">\(\sigma_{\hat{\pi}} = \sigma / \sqrt{n} = \sqrt{\pi(1-\pi)/n}\)</span>이라고 할 수 있습니다.</p>
<p>수리적으로 중심극한정리(Central Limit Theorem, CLT)에 따라서 표본 비율에 대한 표집분포는 무작위 표본의 수가 많으면 많아질수록 정규분포에 근사(approximation)하게 됩니다. 따라서 앞서의 신뢰수준 0.95의 확률에서 표본 비율 <span class="math inline">\(\hat{\pi}\)</span>는 모집단의 비율 <span class="math inline">\(\pi\)</span>를 둘러싼 1.96 <span class="math inline">\(\times\)</span> 표준오차의 구간에 존재한다고 말할 수 있습니다.</p>
<ul>
<li><p>다르게 표현하면, 95%의 확률로 표본의 비율, <span class="math inline">\(\hat{\pi}\)</span> 는 모집단의 비율로부터 표집으로 인한 오차 사이의 구간 사이에 존재한다는 것입니다: <span class="math inline">\(\pi - 1.96\sigma_{\hat{\pi}}\)</span>와 <span class="math inline">\(\pi + 1.96\sigma_{\hat{\pi}}\)</span>.</p></li>
<li><p>따라서 선택된 표본에서 우리는 95%의 확률로 신뢰구간 <span class="math inline">\(\hat{\pi} - 1.96\sigma_{\hat{\pi}}\)</span>와 <span class="math inline">\(\hat{\pi} + 1.96\sigma_{\hat{\pi}}\)</span>이 모집단 비율 <span class="math inline">\(\pi\)</span>를 포함하고 있을 것이라고 주장할 수 있습니다.</p></li>
</ul>
<p>신뢰구간을 구할 때, 앞에서 표준오차를 <span class="math inline">\(\sigma_{\hat{\pi}} = \sigma / \sqrt{n} = \sqrt{\pi(1-\pi)/n}\)</span>라는 공식으로 구할 수 있다고 했습니다만, 사실 이것은 이론적인 주장입니다. 왜냐하면 우리는 모집단의 표준편차, <span class="math inline">\(\sigma\)</span>를 모르기 때문입니다. 때문에 실제로는 우리는 표본비율을 통하여 표집오차를 추정해냅니다. <span class="math display">\[se = \sqrt{\frac{\hat{\pi}(1-\hat{\pi})}{n}}\]</span></p>
<p>그러므로 95% 신뢰수준에서 표본비율의 신뢰구간은 <span class="math inline">\(\hat{\pi}\pm 1.96(se)\)</span>라고 할 수 있습니다. 한 번 예제를 풀어볼까요?</p>
<p>18세부터 22세 사이의 미국인 중 몇 펴센트가 “매우 행복함”이라고 응답했을까요? GSS 데이터를 이용해서 전체 164명 중에서 35명이 “매우 행복함”이라고 응답했다는 것을 확인했다고 합시다.</p>
<ul>
<li><p>표본을 통해서 본 전체 18-22세 중 매우 행복함이라고 응답한 비율은 <span class="math inline">\(\hat{\pi} = 35/164 \approx .213\)</span>입니다. 편의상 0.213이라고 하겠습니다.</p></li>
<li><p>그렇다면 표준오차는 <span class="math inline">\(se = \sqrt{\frac{\hat{\pi}(1-\hat{\pi})}{n}}\)</span>이므로, <span class="math inline">\(\sqrt{0.213(0.787)/164}\)</span>라고 할 수 있습니다. 그 결과값이 0.032라고 합시다.</p></li>
<li><p>95% 신뢰구간은 <span class="math inline">\(0.213 \pm 1.96(0.032)\)</span>가 되므로 <span class="math inline">\(0.213 \pm 0.063\)</span>이라고 할 수 있습니다. 오차한계가 <span class="math inline">\(0.063\)</span>인 것입니다. 이는 구간, <span class="math inline">\((0.15, 0.28)\)</span>을 산출합니다.</p></li>
</ul>
<p>결과적으로 우리는 “매우 행복한” 사람들이 모집단에서 차지할 비율이 95%의 신뢰수준에서 0.15와 0.28, 전체의 15%와 28% 사이에 위치할 것이라고 주장할 수 있습니다.</p>
<p>만약 99% 수준의 신뢰수준에서 신뢰구간을 찾고자 하면 어떻게 될까요? 신뢰구간은 오차한계에 따라 변화합니다. 오차한계는 표준오차를 신뢰수준의 기준값으로 곱해준 결과입니다. 신뢰수준이 변화하면, 기준값도 변화합니다. 99%의 신뢰수준은 양쪽 분포에서 0.5%씩을 차지하므로, 이때 <span class="math inline">\(z\)</span>-score는 2.58입니다. 따라서 99% 수준의 신뢰구간은 위의 예제대로라면 <span class="math inline">\(0.213\pm 2.58(0.032) = 0.213\pm0.083\)</span>이므로, 구간은 <span class="math inline">\((0.13, 0.30)\)</span>이 됩니다. 즉, 신뢰수준이 높아질수록, 신뢰구간은 넓어집니다.</p>
<p>한편, 신뢰구간은 표본의 크기에도 영향을 받습니다. 위의 예제에서 표본의 수가 164개가 아니라 656개라고 생각해보겠습니다. 그러면 먼저 표준오차가 영향을 받습니다. <span class="math inline">\(se = \sqrt{\frac{\hat{\pi}(1-\hat{\pi})}{n}}\)</span>이므로, $  = 0.016$이라는 결과를 얻게 됩니다. 앞서 164개일 때(0.032)와 비교하면 표준오차가 작아진 것을 알 수 있습니다. 따라서 이때는 95% 신뢰수준에서 신뢰구간은 <span class="math inline">\(0.213\pm1.96(0.016) = 0.213\pm0.031\)</span>로 <span class="math inline">\((0.18, 0.24)\)</span>가 됩니다. 즉, 표본의 규모가 클수록 신뢰구간은 작아지는 것을 확인할 수 있습니다.</p>
<p>정리하자면, 만약 우리가 정해진 규모(n)의 표본을 무작위로 반복해서 뽑고, 매번 95% 신뢰구간을 계산한다면, 장기적으로 보았을 때 95% 신뢰구간은 모집단의 비율을 그 구간 안에 포함하게 될 것이라고 기대할 수 있습니다.</p>
<ul>
<li>비율에 대한 신뢰구간의 공식은 다음과 같습니다: <span class="math inline">\(\hat{\pi} \pm z(se) \text{  with  } se = \sqrt{\frac{\hat{pi}(1-\hat{\pi})}{n}}\)</span></li>
</ul>
<p>통계방법은 대규모 관측치를 통하여 표본비율에 대한 표집분포가 정규분포에 근사하여(CLT), 추정값에 대한 표준오차를 최대한 작게 만들 것을 요구합니다. 수리적으로는 분류형 변수에 있어서 최소 30개의 관측치가 존재하고, 그 중 최소 15개씩의 존부(1;0) 결과가 존재한다면 CLT에 따라서 추정할 수 있다고 봅니다. 만약 이러한 조건이 충족되지 않는다면, 표집분포는 왜곡될 수도 있습니다(skewed). 이는 표본비율이 모집단 비율(<span class="math inline">\(\pi\)</span>)을 추정하는 데 쓸모없는 추정치가 될 수 있음을 의미하며, 표준오차도 모집단 수준의 표준오차를 추론하는 데 무용할 수 있다는 것을 의미합니다.</p>
</div>
<div id="평균의-신뢰구간" class="section level4">
<h4><span class="header-section-number">7.1.2.2</span> 평균의 신뢰구간</h4>
<p>이번에는 정량적-연속형 변수일 경우에 신뢰구간을 구하는 방법을 살펴보겠습니다. 관측치의 개수가 많은 무작위 표본에서, 표본의 평균은 모집단 평균 <span class="math inline">\(\mu\)</span>와 표준오차를 둘러싼 정규표집분포(normal sampling distribution)에 근사한다고 할 수 있습니다.
<span class="math display">\[\sigma_{\bar{y}} = \sigma / \sqrt{n}\]</span>
따라서, <span class="math inline">\(P(\mu - 1.96\sigma_{\bar{y}} \leq \bar{y} \mu + 1.96\sigma_{\bar{y}}) = 0.95\)</span>라고 정리할 수 있습니다. 이때 우리는 “95%의 확률로 표본평균이 (알 수 없는) 모집단 평균을 둘러싼 표준편차의 1.96배 구간 내에 위치한다”고 할 수 있습니다.</p>
<p>여기서의 문제는 우리가 표준오차를 모른다는 것입니다. <span class="math inline">\(\sigma\)</span>도 모집단의 표준편차로, 모수이기 때문에 우리가 알지 못합니다. 따라서 우리는 <span class="math inline">\(\sigma\)</span>를 알 수 없기 때문에 이를 표본 데이터로부터의 점추정값으로 대체해서 추정하게 됩니다. 즉, <span class="math display">\[se = s / \sqrt{n}\]</span>이 되는 것입니다. <span class="math inline">\(\mu\)</span>에 대한 95%의 신뢰구간에서 우리는 <span class="math inline">\(\bar{y}\pm1.96(se)\)</span>라고 주장하지만 실상 그것은 <span class="math inline">\(\bar{y}\pm1.96(\frac{s}{\sqrt{n}})\)</span>과 같습니다.</p>
<p>이러한 방법은 어디까지나 표본의 표준편차(<span class="math inline">\(s\)</span>)가 모집단의 표준편차(<span class="math inline">\(\sigma\)</span>)에 대해 좋은 추정값이라고 말할 수 있는 CLT의 근거인 “대규모 관측치”가 가정될 때 가능합니다. 만약 관측치의 개수가 적다면, <span class="math inline">\(\sigma\)</span>를 <span class="math inline">\(s\)</span>로 대체하는 것은 또 다른 오류를 불러올 수 있기 때문에, 신뢰구간이 충분한 너비를 가지지 못할 수 있습니다. 이때 우리는 <span class="math inline">\(z\)</span>-score보다 조금 더 큰 값을 가지는 <span class="math inline">\(t\)</span>-score를 기준치로 대신 사용해줌으로써 표본 규모에 따른 문제를 해결하고자 합니다.</p>
<p>t-분포(<code>Student's t; the t distribution</code>)는 다음과 같은 특징을 가지는 분포입니다.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<ul>
<li><p>0을 중심으로 종 형태(bell-shaped)를 취하는 분포</p></li>
<li><p>표준편차는 1보다 조금 큰 분포; 따라서 표준정규분포보다 양 꼬리가 조금은 더 두꺼운 모습을 보임.</p></li>
<li><p>정확한 형태는 자유도(degree of freedom, df)를 따르는데, 평균을 추론할 때 <span class="math inline">\(df\)</span>는 대개 전체 표본 규모에서 -1을 취한 값을 자유도로 봄.</p></li>
<li><p>자유도가 증가함에 따라 t-분포는 표준정규분포와 거의 흡사해짐.</p>
<ul>
<li><p>자유도가 30을 넘을 때에는 거의 같다고 볼 수 있음.</p></li>
<li><p>만약 자유도가 무한대라면 이는 표준정규분포라고 할 수 있음.</p></li>
</ul></li>
<li><p>평균에 대한 신뢰구간은 오차한계를 비율에 대한 신뢰구간에서처럼 <span class="math inline">\(z(se)\)</span>가 아니라 <span class="math inline">\(t(se)\)</span>로 갖게 됨.</p></li>
</ul>
<p>한 번 t-분포와 z-분포, 그리고 표본 규모에 따른 차이를 한 번 살펴보도록 하겠습니다.</p>
<pre><code>```r
x &lt;- seq(-4, 4, length=1000)
hx &lt;- dnorm(x)
degf &lt;- c(1, 5, 30)
colors &lt;- c(&quot;green&quot;, &quot;blue&quot;, &quot;red&quot;, &quot;black&quot;)
labels &lt;- c(&quot;n = 1&quot;, &quot;n = 5&quot;, &quot;n = 30&quot;, &quot;normal&quot;)
plot(x, hx, type=&quot;l&quot;, lty=1, 
     xlab=&quot;x값의 분포&quot;,
     ylab=&quot;밀도&quot;, main=&quot;t-분포와 z-분포의 비교&quot;)
abline(v = 0)
for (i in 1:3){
  lines(x, dt(x,degf[i]), lwd=2, col=colors[i])
}
legend(&quot;topright&quot;, inset=.05, title=&quot;분포의 종류&quot;,
       labels, lwd=2, lty=c(1, 1, 1, 1), col=colors)
```

&lt;img src=&quot;Kor_BasicStats_files/figure-html/unnamed-chunk-2-1.png&quot; width=&quot;576&quot; style=&quot;display: block; margin: auto;&quot; /&gt;</code></pre>
<p>정규분포를 띄는 모집단으로부터 무작위 표본을 추출했다고 할 때, 95%의 확률로 모집단 평균 <span class="math inline">\(\mu\)</span>에 대한 신뢰구간은 <span class="math display">\[\bar{y} \pm t_{.025}(se) \text{ , with }se = \frac{s}{\sqrt{n}}\]</span>이라고 할 수 있습니다. 이때 <span class="math inline">\(t\)</span>-score에 따라 <span class="math inline">\(df = n-1\)</span>입니다.</p>
<p>모집단의 정규성을 가정하는 것은 표집분포가 표본규모에 상관없이 종의 형태를 딀 것이라는 것을 보장해주기 때문입니다. 아래 그림을 보시면 이해가 더 쉬우리라 생각됩니다.</p>
<p><img src="Chapters_pdf,%20R/plot/population%20distribution.jpg" /></p>
<p>예제로 한 번 평균에 대한 신뢰구간을 살펴보도록 하겠습니다. 관측치가 1,467개라고 할 때, 친한 친구 수의 평균에 대한 95%의 신뢰구간이 <span class="math inline">\((6.8, 8.0)\)</span>이라고 합시다. 그렇다면, 다음 중 어떤 해석이 올바른 해석이라고 할 수 있을까요?</p>
<ol style="list-style-type: decimal">
<li><p>우리는 95%의 확률로 <span class="math inline">\(\bar{y}\)</span>가 6.8과 9.0 사이에 존재한다고 할 수 있다.</p></li>
<li><p><span class="math inline">\(y\)</span>가 친한 친구의 수라고 (이 표본에서) 할 때, 그 값이 95%의 확률로 6.8에서 8.0 사이에 위치한다고 할 수 있다.</p></li>
<li><p>만약 표본규모가 1,467인 무작위 표본들이 반복적으로 추출된다면, 95%의 확률로 <span class="math inline">\(\bar{y}\)</span>가 6.8과 8.0 사이에 떨어질 것이라고 말할 수 있다.</p></li>
<li><p>만약 표본규모가 1,467인 무작위 표본들이 반복적으로 추출된다면, 장기적으로 계산된 신뢰구간들 중 약 95%가 모집단 평균(<span class="math inline">\(\mu\)</span>)을 포함할 것이다.</p></li>
</ol>
<p>정답은 4번입니다. 오해하시면 안 되는 게, 신뢰구간은 어디까지나 표집(sampling)의 개념에 바탕을 두고 있습니다. 하나의 표본에서의 평균이 어느 구간에 존재할 것이라고 주장하는 것이 아니라는 점을 유념하셔야 합니다.</p>
<p><span class="math inline">\(\mu\)</span>에 대한 신뢰구간을 구하는 방법은 모집단의 정규분포 가정이 위배되는 상황에서도 매우 유용합니다. 우리는 직관적으로 신뢰수준이 높을수록 신뢰구간이 넓어진다는 것과 표본규모가 커질수록 더 좁은 신뢰구간을 가진다는 것을 알 수 있습니다.</p>
<p>표집을 수없이 반복해보면, 장기적으로 95% 신뢰수준에서 우리는 <span class="math inline">\(\mu\)</span>에 대한 신뢰구간이 95%의 확률로 실제 모집단의 평균, <span class="math inline">\(\mu\)</span>를 포함하고 있을 것이라고 주장할 수 있습니다. 다시 한 번 강조하지만, 개별 표본의 신뢰구간이 중요한 것이 아니라 이론적으로 모집단에서 수많은 표본들을 뽑아낼 수 있다고 할 때, 그 표본들로부터 얻어내는 통계치의 분포, 표집분포(sampling distribution)이 얼마나 모집단의 모수 추정에 도움이 되는가가 중요합니다.</p>
</div>
</div>
</div>
<div id="유의성-검정significnace-tests" class="section level2">
<h2><span class="header-section-number">7.2</span> 유의성 검정(Significnace Tests)</h2>
<p>추정, 신뢰수준, 신뢰구간의 논의에 이어서 이 절에서는 유의성 검정에 대한 이야기를 해보고자 합니다. 구체적으로는 유의성 검정을 구성하는 다섯 가지 요소들과 평균과 비율에 대한 유의성 검정, 그리고 통계적 유의성을 확인하는 데 주의해야할 오류의 유형들과 유의성 검정의 한계들을 다룰 것입니다.</p>
<div id="유의성-검정을-이루는-다섯-가지-부분" class="section level3">
<h3><span class="header-section-number">7.2.1</span> 유의성 검정을 이루는 다섯 가지 부분</h3>
<p>유의성 검정의 다섯 요소들을 살펴보기에 앞서 이해해야 하는 것은 가설(hypothesis)입니다. 가설이란 연구의 변수들과 관련하여 모수로 표현된 모집단에 대한 예측을 말합니다. 즉, 모집단의 평균, 비율, 또는 상관관계가 어떠할 것이라는 기대를 보여줍니다. 유의성 검정은 데이터를 이용하여 가설로 예측된 값과 모수에 대한 표본 점추정값들을 비교함으로써 가설을 평가하는 절차를 말합니다.</p>
<p>이러한 유의성 검정을 이루는 다섯 가지 요소로는 첫 번째, 가정(assumptions)이 있습니다. 먼저 우리는 우리가 가진 데이터가 정량적(quantitative)인지 혹은 분류형(categorical)인지 알아야 합니다. 그리고 표집 방법으로는 무작위화(randomization)이 가정됩니다. 모집단의 분포는 정규분포(normal distribution)일 것으로 가정되며, 표본의 규모가 커질수록 검정의 타당성도 증가할 것으로 가정합니다.</p>
<p>두 번째 요소는 가설입니다. 우리는 영가설(null hypothesis, <span class="math inline">\(H_0\)</span>)과 대안가설(alternative hypothesis, <span class="math inline">\(H_A\)</span>)를 구분합니다. 영가설이란 모수가 정확하게 ㅇ떠한 값을 가질 것이라는 진술입니다. 대개 유의성 검정에서 영가설은 우리가 기대하는 설명변수의 효과가 없을 것(no effect)이라고 구성됩니다. 반면, 대안가설은 모수의 값이 어떠한 범주의 값에 속할 것이라는 진술로, “효과가 있을 것”이라는 기대를 보여줍니다.</p>
<p>세 번째는 검정통계치(test statistic)입니다. 우리는 가지고 있는 데이터와 영가설의 예측을 비교합니다. 주로 그 방법은 표본의 점추정치와 이를 둘러싼 표준오차의 구간—신뢰구간이 영가설에서 주장하는 모수값을 포함하고 있는지를 살펴보는 것입니다.</p>
<p>네 번째는 유의수준—P-값입니다. P-값은 영가설이 맞을 근거를 확률로 측정한 것입니다. 영가설이 맞을 확률은 곧 대안가설을 겸험적 결과가 지지하지 않을 확률과 같습니다. P-value가 작을수록 영가설이 맞을 확률, 경험적 근거가 적다는 것이므로 이는 영가설을 기각할 가능성이 커진다는 것을 의미합니다.</p>
<p>마지막으로는 결론(conclusion입니다. 만약 결정할 필요가 없이 명백하게 영가설을 지지하는 근거가 미비하다면, P-값을 보고하고 결과를 해석합니다. 하지만 만약 결정이 필요하다면, 우리는 대개 어떤 기준에서 통계적으로 유의하다고 할지 기준점(cutoff points)을 설정하고(예를 들어, 1%나 5% 처럼), P-값이 그 기준점보다 작을 경우에 영가설을 기각합니다. 가장 흔히 받아들여지는 기준점은 0.05입니다.</p>
<ul>
<li>대개는 P-값이 0.05보다 작거나 같을 때, 0.05 수준에서 유의하다라고 검정 결과를 보고합니다.</li>
</ul>
<p>만약 P-값이 충분히 작지 않다면, 우리는 영가설을 기각하는 것을 실패하게 됩니다. 그러면 우리는 영가설이 필연적으로 참이지는 않지만, 그렇다고 그것이 아니라고 할 근거도 충분하지 않으므로 대안가설에 대해 주장하기가 어려워집니다.</p>
<div id="평균에-대한-유의성-검정" class="section level4">
<h4><span class="header-section-number">7.2.1.1</span> 평균에 대한 유의성 검정</h4>
<p>예시를 통해서 평균에 대한 유의성 검정을 살펴보겠습니다. 만약에 <code>A</code>라고 하는 다이어트 방법이 있고, 그 다이어트 방법을 기점으로 몸무게를 측정했다고 해보겠습니다. 그렇다면 <span class="math inline">\(y\)</span>는 몸무개의 변화라고 할 수 있을 것입니다. 그리고 표본의 크기는 17이며, 데이터가 아래와 같이 있다고 가정하겠습니다.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" title="1">y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">11.4</span>, <span class="fl">11.0</span>, <span class="fl">5.5</span>, <span class="fl">9.4</span>, <span class="fl">13.6</span>, <span class="fl">-2.9</span>, <span class="fl">-0.1</span>, <span class="fl">7.4</span>, <span class="fl">21.5</span>, </a>
<a class="sourceLine" id="cb2-2" title="2">       <span class="fl">-5.3</span>, <span class="fl">-3.8</span>, <span class="fl">13.4</span>, <span class="fl">13.1</span>, <span class="fl">9.0</span>, <span class="fl">3.9</span>, <span class="fl">5.7</span>, <span class="fl">10.7</span>)</a>
<a class="sourceLine" id="cb2-3" title="3">n &lt;-<span class="st"> </span><span class="kw">length</span>(y)</a>
<a class="sourceLine" id="cb2-4" title="4">mean &lt;-<span class="st"> </span><span class="kw">mean</span>(y)</a>
<a class="sourceLine" id="cb2-5" title="5">sd &lt;-<span class="st"> </span><span class="kw">sd</span>(y)</a></code></pre></div>
<p>과연 <code>A</code>라는 다이어트 방법이 효과가 있는지 그 근거는 어떻게 확인할 수 있을까요?</p>
<ul>
<li><p>먼저, <span class="math inline">\(\mu\)</span>를 모집단의 평균 몸무게 변화라고 하겠습니다.</p></li>
<li><p>그리고 우리는 영가설, <span class="math inline">\(H_0: \mu = 0\)</span> (효과가 없음)을 <span class="math inline">\(H_A: \mu \neq 0\)</span> (효과가 없지 않음)이라는 연구가설에 대해 검정해보겠습니다.</p></li>
</ul>
<p>주어진 자료의 표본규모(<code>n</code>), 평균(<code>mean</code>), 그리고 표준편차(<code>sd</code>)를 이용해서 간단하게 신뢰구간을 계산해주겠습니다. 모집단 평균에 대한 신뢰구간과 표준오차는 같기 때문에, <span class="math display">\[se = s / \sqrt{n}\]</span>로 계산해주면,</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" title="1">se &lt;-<span class="st"> </span>sd <span class="op">/</span><span class="st"> </span><span class="kw">sqrt</span>(n)</a>
<a class="sourceLine" id="cb3-2" title="2">se</a></code></pre></div>
<pre><code>## [1] 1.73593</code></pre>
<p>위와 같은 결과를 얻게 되고, 주어진 자유도(17 -1 = 16)에서 검정통계량은 <span class="math inline">\(t = \frac{\bar{y}-\mu_0}{se}\)</span>라고 할 수 있습니다. 따라서 그 결과는 아래와 같이 계산할 수 있습니다.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" title="1">t &lt;-<span class="st"> </span>(mean <span class="op">-</span><span class="st"> </span><span class="dv">0</span>)<span class="op">/</span>se</a>
<a class="sourceLine" id="cb5-2" title="2">t</a></code></pre></div>
<pre><code>## [1] 4.184908</code></pre>
<p>그렇다면 이 t-값은 유의수준과 어떠한 관계에 있을까요? 우리는 t-값이 계산한 결과보다 클 확률을 양측꼬리 검정으로 계산해볼 수 있습니다.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" title="1"><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">pt</span>(<span class="op">-</span><span class="kw">abs</span>(t), <span class="dt">df =</span> n <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</a></code></pre></div>
<pre><code>## [1] 0.0007002531</code></pre>
<p>해석하자면, 만약 영가설이 참이라면 영가설값(0)으로부터 최소 약 4.18배의 표준오차 범위 내에서 표본평균을 얻을 확률이 약 0.0007이라는 것이라고 할 수 있습니다. 결국, 우리는 이를 통해 모집단 평균이 0과 다를 것이라는 강력한 근거를 확보하게 되는 것입니다.</p>
<ul>
<li><p>양측꼬리 검정에서 P-값이 0.05보다 작거나 같을 때, 모집단 평균에 대한 95% 신뢰구간은 모집단 평균에 대한 영가설의 값(예를 들어 효과가 없음을 보여주는 0)을 포함하지 않을 것입니다.</p></li>
<li><p>만약 P-값이 0.05보다 크다면, 95% 신뢰구간은 필연적으로 모집단 평균에 대한 영가설의 값을 포함하고 있을 것입니다.</p></li>
<li><p>이러한 점에서 신뢰구간은 실제 모집단 평균의 값에 대한 더 많은 정보를 제공합니다.</p></li>
</ul>
<p>그렇다면 단측꼬리 검정은 어떠한 차이가 있을까요? 단측꼬리 검정은 모집단 평균에 대한 영가설에 방향성을 부과한 것이라고 이해할 수 있습니다. 예를 들어, 앞서의 예제에서 다이어트 방법 <code>A</code>에 따라 몸무게의 변화의 평균은 0보다 클 것(<span class="math inline">\(H_0: \mu &gt; 0\)</span>)이라는 것입니다. 만약 t-값이 우측꼬리에서 멀어질수록 이 가설을 데이터가 지지하므로, P-값은 우측꼬리에 대한 확률이라고 할 수 있습니다.</p>
<ul>
<li><p><span class="math inline">\(n = 4\)</span>(df <span class="math inline">\(=3\)</span>)일 때, <span class="math inline">\(t = 2.0\)</span>라고 해보겠습니다. 그렇다면 P-값은 <span class="math inline">\(P = P(t &gt; 2.0)\)</span>이므로 0.07이라고 할 수 있습니다.</p></li>
<li><p>그렇다면 대안가설(<span class="math inline">\(H_A: \mu &lt; 0\)</span>)의 확률은 좌측꼬리를 기준으로 P-값이 <span class="math inline">\(P = P(t &lt; 2.0)\)</span>이므로 0.93이 됩니다.</p></li>
</ul>
<p>일반적으로 양측꼬리 검정이 더 흔하게 사용됩니다. 왜냐하면 관계 양상의 존재—인과적 효과를 살펴보기 위해 가설을 수립하는 경우가 더 많기 때문입니다.</p>
<p>이렇게 영가설과 대안가설을 수립하고 나서는 “결정”을 해야합니다. 유의수준(significance level)이라 불리는 <span class="math inline">\(\alpha\)</span>-level은 고정된 수입니다. 우리는 이 유의수준에 근거하여,</p>
<ul>
<li><p>P-값이 <span class="math inline">\(\alpha\)</span> 값보다 작거나 같으면 “영가설을 기각한다.” 또는,</p></li>
<li><p>P-값이 <span class="math inline">\(\alpha\)</span> 값보다 크면 “영가설을 기각하지 않는다.”라는 결정을 내릴 수 있습니다.</p></li>
</ul>
<p>우리는 “영가설을 채택한다”라는 표현보다는 “<strong>영가설을 기각하지 않는다</strong>”라고 말합니다. 왜냐하면 영가설이 맞다는 것이 아니라 단지 우리가 확인한 것은 영가설의 값이 신뢰구간에 포함될 확률이 기대보다 높게 나타났을 따름입니다. 우리는 과연 어떤 설명변수의 효과가 존재하는지, 존재하지 않는지에 대해서 확언할 수가 없습니다.</p>
<p>한편, 이와 같은 유의성 검정에 대한 표본 규모의 효과를 살펴볼 필요가 있습니다. 대개는 관측치가 30개를 초과할 때, CLT로 인하여 정규분포에 대한 가정은 크게 중요하지 않다고 봅니다. 다만, 표본 규모가 30개보다 작은, 소규모 표본일때는 양측꼬리 t-검정을 수행하는 것이 정규분포 가정이 위배되는 것을 일부 방어할 수 있습니다. t-분포는 소규모 사례 분포에 대한 분포를 가정하고 있으니까요.</p>
<p>표본의 규모가 커질수록 검정 통계치도 더 커집니다. 왜냐하면 공식 상 분모가 표준오차인데, 표준오차는 표본의 규모가 커질수록 감소하기 때문입니다. 따라서 표본의 규모가 커질수록 우리는 자동적으로 P-값이 작아지는 것을 확인할 수 있습니다. 데이터가 많을수록 근거를 확보하기가 쉬워진다는 것을 의미합니다. <strong>그러나 표본 규모가 클 때, 통계적 유의성은 결코 실질적 유의성과 같은 의미는 아닙니다.</strong> 통계적으로 유의하다고 해서 과연 그 효과가 실질적으로 유의미한 것일까요? 예시를 들어보겠습니다.</p>
<p>아까와 같이 몸무게 변화에 대해 평균 <span class="math inline">\(1,0\)</span>, 표준편차 <span class="math inline">\(2.0\)</span>, 사례 수가 400개라고 해보겠습니다. 그렇다면 표준오차는 <span class="math inline">\(2.0/\sqrt{400} = 0.1\)</span>가 되고, t-값은 <span class="math inline">\((1.0 - 0)/0.1 = 10.0\)</span>이 됩니다. 그럼 P-값은 <span class="math inline">\(0.00000\)</span>…으로 엄청 작게 나타날 것입니다. 그리고 95% 신뢰구간은 <span class="math inline">\((0.8, 1.2)\)</span>입니다. 결과적으로는 다이어트 방법 <code>A</code>는 몸무게 변화에 긍정적인 효과가 있는 것으로 나타났지만 실질적으로 그 효과는 매우 작습니다. 따라서 통계적으로는 유의미할지라도 실질적으로는 유의하지 않을 수도 있습니다.</p>
</div>
<div id="비율에-대한-유의성-검정" class="section level4">
<h4><span class="header-section-number">7.2.1.2</span> 비율에 대한 유의성 검정</h4>
<p>접근</p>

</div>
</div>
</div>
</div>







<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>유의성 검정 부분에서 한 번 더 짚고 넘어갈 것이지만, 여기에서 의미하는 신뢰수준이란 표본과 모집단, 그리고 표집(sampling)의 문제와 관련이 있습니다. 우리가 얻는 특정한 추정량들은 표집 방법에 따라 충분히 표본이 모집단에 대해 대표성을 가진다고 할 때, 신뢰할 수 있는 결과로 받아들여집니다. 그럼에도 불구하고, 모집단에서 표본을 뽑아낸다는 본연적 한계로 인하여 우리는 표본에서 얻어낸 결과가 모집단을 제대로 보여주지 못했을 결과를 감안해야만 합니다. 신뢰구간이란 이론적으로 총 몇 번의 표집과정을 되풀이했을 때, 그 중 얼마만큼의 잘못된 추정을 가질 확률을 의미합니다. 예를 들어, 100번의 표집을 거쳐 5번의 다른 결과를 얻었을 때, 우리는 95%의 확률로 그 결과값을 신뢰할 수 있다고 보는 것입니다.<a href="better-understanding-for-linear-model.html#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>t-분포를 이용한 방법은 더블린의 기네스 맥주공장에서 일하던 통계학자 William Gosset에 의해서 1908년에 고안되었습니다. 회사 정책 상 자신의 이름으로 논문을 내는 것이 불가능했기 때문에, Gosset은 가명으로 Student라는 이름을 이용하여 논문을 작성하였습니다. 때로 <code>Student's t</code>라고 불리는 이유는 그 때문입니다. 공장에서 Gosset에게는 테스트할 맥주 표본이 매우 소수만 제공되었기 때문에, 그는 그 표본사례를 가지고 기존의 표준오차 공식의 정규 <span class="math inline">\(z\)</span>-score에 사용할 수 없다는 것을 알게 되었습니다. 그 결과가 소수의 사례로 구성된 꼬리가 정규표준분포에 비해 약간 더 두꺼운 t-분포입니다.<a href="better-understanding-for-linear-model.html#fnref2" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="intoduction-to-simple-linear-regression-model.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/06-AdvancedLM.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["Kor_BasicStats.pdf", "Kor_BasicStats.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
